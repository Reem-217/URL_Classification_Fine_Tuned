{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6i9k_5oiXhb"
   },
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j47m4knccs9X"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bL4-3ypnihx_"
   },
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "f3f252774f0b4134ae72fb06c3320094",
      "42c53530b2f94081af6765412d99ff30",
      "2aba71a945994c36b6f7a2a33007802b",
      "4f53b2f6cb3c45e284ac77089ccfd14c",
      "88b4657345a64460aba62f92b36dc7c7",
      "313a31ff68d044c6897d46a4b20332f2",
      "8fd1aa0b8e9b428490e78f02a6eadef6",
      "24c7b5b7682b4c56bd2d1f388e40a12c",
      "8bc60062c56f4c71904718b0217b8b74",
      "6a3a00e579654aebb7a4561555e7d46e",
      "9f558406c8ee4a469f0ce44df2dde1ca",
      "b16fd4351d1c4379a4da0ebe4f19929b",
      "bb5e178b70e04a93937f32877d8f2e4b",
      "795b0a64f1454b67b85d770cfab9cff6",
      "ff1344ac09924d00980c33b1134c4b96",
      "4c5844c974274942a8cad603ff618c8e",
      "07a9ca0067f24ef3b3bd90b2edf6bc39",
      "59c60de893664afdbb84fe57ea8b26b3",
      "aadd0737c374432095565e90bbe1b95f",
      "02b46ad3c1e84420a2517269677fd90c",
      "a8adb0c8e0074e249d6080056e9de15e",
      "d8ce77bdb70e4be392f5474463da2e95",
      "5fa55f9a18db47b5b591965552944917",
      "353306751b214b6286ac269b61676f73",
      "b06f01ce8d32455fbd2d144f2be3a31c",
      "0944f47fdc6c4547b51a3649d0c41675",
      "3abc4eddf93242d4af041aaca51ccecc",
      "fbbdd720797e4ea190cb5332a6fb9a96",
      "9da4ac75fd5041f5b1ccd28f7c1a9c5d",
      "14087d54183e4984a14e8b19fab412d3",
      "d8568c399f5144b69ed65b7eee0b7787",
      "6bb3adfb2ada4f4885a1d97254dbab39",
      "dbd2d027cae54d5d87c89709e096d77f",
      "56b16d97585646ca9d83d0b3c01ff256",
      "a7ab647921bf49fe91b7dea4f8545126",
      "2fc350c573334577b4cb2746ca0c926e",
      "8088c9fd853d46248818fac744ca7f9b",
      "897e6027de2541c1b170f9e852e936b0",
      "a09e91c13ac440399cfc1e46483154d2",
      "65fd6e5b35d94f0791faabbbbb018c32",
      "6ae3fd6c10c74a11873377ba9fda5ebe",
      "ce36333af20c4b41a0ccef19fd3eb9bc",
      "6d001e6066ee4d23b6d50a7d0d5f08dc",
      "6ad048da35c445d8a3893a6658594e07",
      "ea739487a369449ea264f526f0829e6f",
      "cc484f09ebda4784bafe542d1857a963",
      "35b6911c61064d92b7bb78ff43185eef",
      "2a57f7f670ca4eaa921aef6d34d82dc8",
      "795885a5341c4e79a0764ef5fe6dfecd",
      "f0afc0ebfd194e32b260a6cc5fc59023",
      "4a58a365b1534ff99a902fd1fbdd97e3",
      "726e722db58f40f1803f95cf9c1fb37d",
      "73cc4d1b3e5248b5838c13ea4ee3a934",
      "26ef02aab8a84bc49e9bce5852e3de05",
      "63f7206e2c74490db590c3679035f9ef",
      "c364ddc85e3a4c2aaf1530f1cf54604d",
      "213a73d392ee42e4b0e445bea219743b",
      "11c899a3ee604b8989b49825ca40dcce",
      "e88296e69a7a4308b1ba943e20be77d8",
      "5a70922a97234915a0b91465f91c6105",
      "09d1689ff1d74d259246bf7632d4a55d",
      "12900d12853b446f9dcbdfb99e44b8d6",
      "20be047db9a04a78af67b153628427ac",
      "a2d606bb3101488bbf76b89cfefbd072",
      "8831136d947a4cd6b46229494ca90ee3",
      "2a231c613d4c41b59f828513e23bdb6f",
      "c8975cd51fa249a1bc0533ffee13f056",
      "1f8bc92e941e4aeeb2823fa6d9dc317a",
      "039e9f2ed7bc4d04ad231c5c856d6a48",
      "c7c02a192a0e44778899f63357bdd3a8",
      "d5023e23e5eb46a8a4c9cac5588b6b33",
      "eac2bedee29c4f5fb586dd2a96797250",
      "d98ce7c9e6634e348e8da40475766b57",
      "8d4e503be0bf496fa5b07c0a95b22974",
      "21fa06f498284d229b8cea04fa87d2ef",
      "86d9400481bd41bbbfcd985f9839919c",
      "93d4548a39854bc287a680a16c681f8d"
     ]
    },
    "id": "uRr4rrnQdV1R",
    "outputId": "03fc70a6-8f36-4997-d185-f0d0300bed36"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f252774f0b4134ae72fb06c3320094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16fd4351d1c4379a4da0ebe4f19929b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/98.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa55f9a18db47b5b591965552944917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/21.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b16d97585646ca9d83d0b3c01ff256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/24.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea739487a369449ea264f526f0829e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c364ddc85e3a4c2aaf1530f1cf54604d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8975cd51fa249a1bc0533ffee13f056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dict= load_dataset(\"shawhin/phishing-site-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PELBe0ZFipC5"
   },
   "source": [
    "Load The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "9e7232ee6799489b985f3bb22fd94a50",
      "64443dae4fc04904917eebabbad7e305",
      "829bb93ff84141d79bc8e367d0a60829",
      "3db4daebee9d4da68080656e4a011ccc",
      "2694b0d1d83d436aa9794f57a072de57",
      "da1c233ed7704dfbabd24d72ee530ceb",
      "c36be8cf99724a9981ecde2f993e532a",
      "2447021a7d97400fbeccac32f927fe63",
      "4fcb14564fd74feebe2eb25c6b91ab9a",
      "faee4c7ec47c4132946443ccfe48e8b8",
      "0a4df9f0e8c248d6b5a5182be4d9e36b",
      "49755ff2406641ffa8e4dee1e9269aa6",
      "ff584e7dd5094214927b3920372259db",
      "3708c1c638744d3997fd8b5558f7d753",
      "14c3f0d49ad3457e96caa3558050f77f",
      "4665c34f59044ea896fa5a0470079bdb",
      "77cd14cdd81d450d826aa199449056ad",
      "dfc416a8683047f8b2fd46ed9006aaa5",
      "3d463800141a4a04b36e38a4ea8205c3",
      "d334efe37f5e4272adf813677bf6bde1",
      "93a67412005c4cda935cc4e89b43ee89",
      "c6919ba85766426baf55255705be0089",
      "3ffc7b1b78cf4f2fb1201e57f0daaf1e",
      "d36ece29c0604f3ca21b1a53cc1c2941",
      "fa709f1e76054f51819c6ec41a9f5345",
      "729e64c2a31a4cb0a437792cd0fe34c3",
      "8c69ef2c09094b4ca49bcafed3c0df84",
      "f66bbe03edf740859465c9ec0c62939f",
      "c766a49453f2472f9c53ffba6ed0b16a",
      "1c4a9c2390264e54a9b46b1e8436bf22",
      "5c8496a55cc04a5485743a07a080846f",
      "7145325ce4aa4228b805be43e44fbdc6",
      "348e7d98b7634a59a1c255fe2363e056",
      "1128b18330f3434c903f4679e840d15c",
      "7fd8ca062bcd4d17b1763d92c227feab",
      "f1ed5bcfb20b49718ad7105d51a89ef4",
      "6e54e17f9e01490c9e1c30f729af66bf",
      "29708d664c2e40809d8d435f4cb199c0",
      "82a17cf54b4f4c63a9434c2a5e7dc118",
      "8364ee85c44e4beaa59d5fd7ce25e281",
      "1d42558892dd48ca9c49f228b97c4d49",
      "3418208355844ded8cc7c8de8903a47b",
      "fa91aeb0bca9459a87200a335723453f",
      "d421c9ab835b44dc8cb5da3c0ba1bddb"
     ]
    },
    "id": "--nxQ7lVdoX5",
    "outputId": "142599e3-8b66-4685-98b4-073ee225355e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7232ee6799489b985f3bb22fd94a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49755ff2406641ffa8e4dee1e9269aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffc7b1b78cf4f2fb1201e57f0daaf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1128b18330f3434c903f4679e840d15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "tokenizer= AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHV7NhModygu",
    "outputId": "498340e6-463e-4b84-bcce-0d679d3802c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id_to_label={0:\"Safe\", 1:\"Unsafe\"}\n",
    "label_to_id={\"Safe\":0, \"Unsafe\":1}\n",
    "model=AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path, num_labels=2,\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwVgTlA6eUOw",
    "outputId": "49111b99-21b0-490f-cca1-e6f68ad56a76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight True\n",
      "bert.embeddings.position_embeddings.weight True\n",
      "bert.embeddings.token_type_embeddings.weight True\n",
      "bert.embeddings.LayerNorm.weight True\n",
      "bert.embeddings.LayerNorm.bias True\n",
      "bert.encoder.layer.0.attention.self.query.weight True\n",
      "bert.encoder.layer.0.attention.self.query.bias True\n",
      "bert.encoder.layer.0.attention.self.key.weight True\n",
      "bert.encoder.layer.0.attention.self.key.bias True\n",
      "bert.encoder.layer.0.attention.self.value.weight True\n",
      "bert.encoder.layer.0.attention.self.value.bias True\n",
      "bert.encoder.layer.0.attention.output.dense.weight True\n",
      "bert.encoder.layer.0.attention.output.dense.bias True\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.0.intermediate.dense.weight True\n",
      "bert.encoder.layer.0.intermediate.dense.bias True\n",
      "bert.encoder.layer.0.output.dense.weight True\n",
      "bert.encoder.layer.0.output.dense.bias True\n",
      "bert.encoder.layer.0.output.LayerNorm.weight True\n",
      "bert.encoder.layer.0.output.LayerNorm.bias True\n",
      "bert.encoder.layer.1.attention.self.query.weight True\n",
      "bert.encoder.layer.1.attention.self.query.bias True\n",
      "bert.encoder.layer.1.attention.self.key.weight True\n",
      "bert.encoder.layer.1.attention.self.key.bias True\n",
      "bert.encoder.layer.1.attention.self.value.weight True\n",
      "bert.encoder.layer.1.attention.self.value.bias True\n",
      "bert.encoder.layer.1.attention.output.dense.weight True\n",
      "bert.encoder.layer.1.attention.output.dense.bias True\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.1.intermediate.dense.weight True\n",
      "bert.encoder.layer.1.intermediate.dense.bias True\n",
      "bert.encoder.layer.1.output.dense.weight True\n",
      "bert.encoder.layer.1.output.dense.bias True\n",
      "bert.encoder.layer.1.output.LayerNorm.weight True\n",
      "bert.encoder.layer.1.output.LayerNorm.bias True\n",
      "bert.encoder.layer.2.attention.self.query.weight True\n",
      "bert.encoder.layer.2.attention.self.query.bias True\n",
      "bert.encoder.layer.2.attention.self.key.weight True\n",
      "bert.encoder.layer.2.attention.self.key.bias True\n",
      "bert.encoder.layer.2.attention.self.value.weight True\n",
      "bert.encoder.layer.2.attention.self.value.bias True\n",
      "bert.encoder.layer.2.attention.output.dense.weight True\n",
      "bert.encoder.layer.2.attention.output.dense.bias True\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.2.intermediate.dense.weight True\n",
      "bert.encoder.layer.2.intermediate.dense.bias True\n",
      "bert.encoder.layer.2.output.dense.weight True\n",
      "bert.encoder.layer.2.output.dense.bias True\n",
      "bert.encoder.layer.2.output.LayerNorm.weight True\n",
      "bert.encoder.layer.2.output.LayerNorm.bias True\n",
      "bert.encoder.layer.3.attention.self.query.weight True\n",
      "bert.encoder.layer.3.attention.self.query.bias True\n",
      "bert.encoder.layer.3.attention.self.key.weight True\n",
      "bert.encoder.layer.3.attention.self.key.bias True\n",
      "bert.encoder.layer.3.attention.self.value.weight True\n",
      "bert.encoder.layer.3.attention.self.value.bias True\n",
      "bert.encoder.layer.3.attention.output.dense.weight True\n",
      "bert.encoder.layer.3.attention.output.dense.bias True\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.3.intermediate.dense.weight True\n",
      "bert.encoder.layer.3.intermediate.dense.bias True\n",
      "bert.encoder.layer.3.output.dense.weight True\n",
      "bert.encoder.layer.3.output.dense.bias True\n",
      "bert.encoder.layer.3.output.LayerNorm.weight True\n",
      "bert.encoder.layer.3.output.LayerNorm.bias True\n",
      "bert.encoder.layer.4.attention.self.query.weight True\n",
      "bert.encoder.layer.4.attention.self.query.bias True\n",
      "bert.encoder.layer.4.attention.self.key.weight True\n",
      "bert.encoder.layer.4.attention.self.key.bias True\n",
      "bert.encoder.layer.4.attention.self.value.weight True\n",
      "bert.encoder.layer.4.attention.self.value.bias True\n",
      "bert.encoder.layer.4.attention.output.dense.weight True\n",
      "bert.encoder.layer.4.attention.output.dense.bias True\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.4.intermediate.dense.weight True\n",
      "bert.encoder.layer.4.intermediate.dense.bias True\n",
      "bert.encoder.layer.4.output.dense.weight True\n",
      "bert.encoder.layer.4.output.dense.bias True\n",
      "bert.encoder.layer.4.output.LayerNorm.weight True\n",
      "bert.encoder.layer.4.output.LayerNorm.bias True\n",
      "bert.encoder.layer.5.attention.self.query.weight True\n",
      "bert.encoder.layer.5.attention.self.query.bias True\n",
      "bert.encoder.layer.5.attention.self.key.weight True\n",
      "bert.encoder.layer.5.attention.self.key.bias True\n",
      "bert.encoder.layer.5.attention.self.value.weight True\n",
      "bert.encoder.layer.5.attention.self.value.bias True\n",
      "bert.encoder.layer.5.attention.output.dense.weight True\n",
      "bert.encoder.layer.5.attention.output.dense.bias True\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.5.intermediate.dense.weight True\n",
      "bert.encoder.layer.5.intermediate.dense.bias True\n",
      "bert.encoder.layer.5.output.dense.weight True\n",
      "bert.encoder.layer.5.output.dense.bias True\n",
      "bert.encoder.layer.5.output.LayerNorm.weight True\n",
      "bert.encoder.layer.5.output.LayerNorm.bias True\n",
      "bert.encoder.layer.6.attention.self.query.weight True\n",
      "bert.encoder.layer.6.attention.self.query.bias True\n",
      "bert.encoder.layer.6.attention.self.key.weight True\n",
      "bert.encoder.layer.6.attention.self.key.bias True\n",
      "bert.encoder.layer.6.attention.self.value.weight True\n",
      "bert.encoder.layer.6.attention.self.value.bias True\n",
      "bert.encoder.layer.6.attention.output.dense.weight True\n",
      "bert.encoder.layer.6.attention.output.dense.bias True\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.6.intermediate.dense.weight True\n",
      "bert.encoder.layer.6.intermediate.dense.bias True\n",
      "bert.encoder.layer.6.output.dense.weight True\n",
      "bert.encoder.layer.6.output.dense.bias True\n",
      "bert.encoder.layer.6.output.LayerNorm.weight True\n",
      "bert.encoder.layer.6.output.LayerNorm.bias True\n",
      "bert.encoder.layer.7.attention.self.query.weight True\n",
      "bert.encoder.layer.7.attention.self.query.bias True\n",
      "bert.encoder.layer.7.attention.self.key.weight True\n",
      "bert.encoder.layer.7.attention.self.key.bias True\n",
      "bert.encoder.layer.7.attention.self.value.weight True\n",
      "bert.encoder.layer.7.attention.self.value.bias True\n",
      "bert.encoder.layer.7.attention.output.dense.weight True\n",
      "bert.encoder.layer.7.attention.output.dense.bias True\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.7.intermediate.dense.weight True\n",
      "bert.encoder.layer.7.intermediate.dense.bias True\n",
      "bert.encoder.layer.7.output.dense.weight True\n",
      "bert.encoder.layer.7.output.dense.bias True\n",
      "bert.encoder.layer.7.output.LayerNorm.weight True\n",
      "bert.encoder.layer.7.output.LayerNorm.bias True\n",
      "bert.encoder.layer.8.attention.self.query.weight True\n",
      "bert.encoder.layer.8.attention.self.query.bias True\n",
      "bert.encoder.layer.8.attention.self.key.weight True\n",
      "bert.encoder.layer.8.attention.self.key.bias True\n",
      "bert.encoder.layer.8.attention.self.value.weight True\n",
      "bert.encoder.layer.8.attention.self.value.bias True\n",
      "bert.encoder.layer.8.attention.output.dense.weight True\n",
      "bert.encoder.layer.8.attention.output.dense.bias True\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.8.intermediate.dense.weight True\n",
      "bert.encoder.layer.8.intermediate.dense.bias True\n",
      "bert.encoder.layer.8.output.dense.weight True\n",
      "bert.encoder.layer.8.output.dense.bias True\n",
      "bert.encoder.layer.8.output.LayerNorm.weight True\n",
      "bert.encoder.layer.8.output.LayerNorm.bias True\n",
      "bert.encoder.layer.9.attention.self.query.weight True\n",
      "bert.encoder.layer.9.attention.self.query.bias True\n",
      "bert.encoder.layer.9.attention.self.key.weight True\n",
      "bert.encoder.layer.9.attention.self.key.bias True\n",
      "bert.encoder.layer.9.attention.self.value.weight True\n",
      "bert.encoder.layer.9.attention.self.value.bias True\n",
      "bert.encoder.layer.9.attention.output.dense.weight True\n",
      "bert.encoder.layer.9.attention.output.dense.bias True\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.9.intermediate.dense.weight True\n",
      "bert.encoder.layer.9.intermediate.dense.bias True\n",
      "bert.encoder.layer.9.output.dense.weight True\n",
      "bert.encoder.layer.9.output.dense.bias True\n",
      "bert.encoder.layer.9.output.LayerNorm.weight True\n",
      "bert.encoder.layer.9.output.LayerNorm.bias True\n",
      "bert.encoder.layer.10.attention.self.query.weight True\n",
      "bert.encoder.layer.10.attention.self.query.bias True\n",
      "bert.encoder.layer.10.attention.self.key.weight True\n",
      "bert.encoder.layer.10.attention.self.key.bias True\n",
      "bert.encoder.layer.10.attention.self.value.weight True\n",
      "bert.encoder.layer.10.attention.self.value.bias True\n",
      "bert.encoder.layer.10.attention.output.dense.weight True\n",
      "bert.encoder.layer.10.attention.output.dense.bias True\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.10.intermediate.dense.weight True\n",
      "bert.encoder.layer.10.intermediate.dense.bias True\n",
      "bert.encoder.layer.10.output.dense.weight True\n",
      "bert.encoder.layer.10.output.dense.bias True\n",
      "bert.encoder.layer.10.output.LayerNorm.weight True\n",
      "bert.encoder.layer.10.output.LayerNorm.bias True\n",
      "bert.encoder.layer.11.attention.self.query.weight True\n",
      "bert.encoder.layer.11.attention.self.query.bias True\n",
      "bert.encoder.layer.11.attention.self.key.weight True\n",
      "bert.encoder.layer.11.attention.self.key.bias True\n",
      "bert.encoder.layer.11.attention.self.value.weight True\n",
      "bert.encoder.layer.11.attention.self.value.bias True\n",
      "bert.encoder.layer.11.attention.output.dense.weight True\n",
      "bert.encoder.layer.11.attention.output.dense.bias True\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "bert.encoder.layer.11.intermediate.dense.weight True\n",
      "bert.encoder.layer.11.intermediate.dense.bias True\n",
      "bert.encoder.layer.11.output.dense.weight True\n",
      "bert.encoder.layer.11.output.dense.bias True\n",
      "bert.encoder.layer.11.output.LayerNorm.weight True\n",
      "bert.encoder.layer.11.output.LayerNorm.bias True\n",
      "bert.pooler.dense.weight True\n",
      "bert.pooler.dense.bias True\n",
      "classifier.weight True\n",
      "classifier.bias True\n"
     ]
    }
   ],
   "source": [
    "#layers\n",
    "for name, param in model.named_parameters():\n",
    "  print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZYR3dSki2_y"
   },
   "source": [
    "Freeze base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xSI_MGme0DJ"
   },
   "outputs": [],
   "source": [
    "for name, param in model.base_model.named_parameters():\n",
    "  param.requires_grad=False\n",
    "\n",
    "for name, param in model.base_model.named_parameters():\n",
    "  if \"pooler\" in name:\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaBf2vwMi_kz"
   },
   "source": [
    "Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yj6XSKjEfYB2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_func(example):\n",
    "  return tokenizer(example[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "3b639d5922534088bbd80b3b677bca5b",
      "cc156a18d0d342c596fb5009f5824860",
      "5b4a2d7e64c14f08b5e7fa124e106621",
      "924ca05915a843fe8b6c55a6d49a64a8",
      "b370d91782914b079bf55c48af329a4f",
      "289fd41cad3946a68907647279f8135f",
      "095439cfe0ef4f1b878957d51aa8267a",
      "3a9b5a38b15847dc96e42f1a60708e68",
      "c6e08e12429543ba8ae97227bbadced1",
      "e40851015525483ba922059bc570df25",
      "bf84fdd7c5e74ffc8dc629b20fa5adad",
      "6798ef6bab754b2e9633738f7d054c73",
      "eeb511a0c28847c1a1d3821fea8687d5",
      "c2c47d45f2a14216818e94b95d30341f",
      "3f39c09bf8ac4f9ba58db42824249984",
      "9439766b803b44c2b9b10d0275569ae3",
      "b2c7759a91e448228edfaeb882a886db",
      "2e9cbde4d7fc4d89b9d429ab20d01432",
      "ec1d9bd55b274f3d9d142a4dacbb75b3",
      "b96ba7511a4345e6bf498190e30a98d7",
      "393d2de9ed5a4e9a84b68eaa34767528",
      "d9587b2411a94fd89077af38e010fb89",
      "732852d2a72b4a7b896418fc30915b25",
      "9abf0dcbfcd2473381d652de3ebafee4",
      "f9ce99bd9bfc4aa8994a0780149117fd",
      "647a8f1782544439bc44dafc22c562fc",
      "f236dfe9ddf943e7802259a89b414b22",
      "8ce8193290774e6588fcce6737760e7f",
      "887803f4eecb4e95b47d368b079740c5",
      "201f284e139348cf940dcc3764450008",
      "e6e11a573a624c5f8c16e7ef462a1ec5",
      "09217bb8d4ca4a31bdbdff625649dcf7",
      "df7999d63888489fbb3950fa11654696"
     ]
    },
    "id": "7tq6wc_rgD6S",
    "outputId": "dadb6c8d-98a3-471b-d824-3ac8e4652824"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b639d5922534088bbd80b3b677bca5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6798ef6bab754b2e9633738f7d054c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732852d2a72b4a7b896418fc30915b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data=dataset_dict.map(preprocess_func,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7uxsotEgKxa"
   },
   "outputs": [],
   "source": [
    "#padding\n",
    "data_collator= DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VukBlKfKjNoG"
   },
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "c9b2c17c7e404b25bc6bbede852ab923",
      "b484ca375971400f94fee5d88d195c85",
      "cb7c4e0c7dac45f0a44a136302c1ff6b",
      "dfe73ac592764dfabc6e16f57e0b9314",
      "84081d137ad441b68c8b3cdda20bc6e8",
      "ecea34762d0449e1a2600d642a96a1fc",
      "a94ed2bf509142cfad65e50f4a004133",
      "0a09bc2e778342d58fe9d341bba1d456",
      "f3df36048da1452faf4fc3ab81de19df",
      "226af9791f7e48059dbba55d1a08209d",
      "928d877eaa2e4aa79d9c649fa989e406",
      "9154fdf23a944334be490393f88aeefe",
      "3a9a020a26854a59a57e42936e9eb8e2",
      "42965a8317a44ff9883964d71ff34c33",
      "101fc10291f2465587e08a6d191706de",
      "49a983384cd641e7b360f6a0abcf35c4",
      "7c94cdb1d07e401fb9394cce876eb276",
      "580c15ddc8bf455d8fbef1b058d807c9",
      "d0797163b3404c4da2b1b2f072a5e874",
      "69657e7891954581afb3bb752abbd17f",
      "34460a4d280f4980a511c49b671c4da2",
      "32760aed87354134b6886244c82375a6"
     ]
    },
    "id": "nly4Hqx1gUht",
    "outputId": "3effd736-6285-499d-d2a5-f90970171a24"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b2c17c7e404b25bc6bbede852ab923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9154fdf23a944334be490393f88aeefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/9.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "auc_score = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # get predictions\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # apply softmax to get probabilities\n",
    "    probabilities = np.exp(predictions) / np.exp(predictions).sum(-1, keepdims=True)\n",
    "    # use probabilities of the positive class for ROC AUC\n",
    "    positive_class_probs = probabilities[:, 1]\n",
    "    # compute auc\n",
    "    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs, references=labels)['roc_auc'],3)\n",
    "\n",
    "    # predict most probable class\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    # compute accuracy\n",
    "    acc = np.round(accuracy.compute(predictions=predicted_classes, references=labels)['accuracy'],3)\n",
    "\n",
    "    return {\"Accuracy\": acc, \"AUC\": auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn25AxQBjbm7"
   },
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkraHou7gnNB"
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 2e-4\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert-phishing-classifier_teacher\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "id": "kXnphemGgsfs",
    "outputId": "41a59936-05e5-4d56-aa10-cd419b9048bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-25805d4bc91c>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mreem-ref3aat7890\u001b[0m (\u001b[33mreem-ref3aat7890-damietta-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250420_184518-6f9m3zzn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/reem-ref3aat7890-damietta-university/huggingface/runs/6f9m3zzn' target=\"_blank\">bert-phishing-classifier_teacher</a></strong> to <a href='https://wandb.ai/reem-ref3aat7890-damietta-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/reem-ref3aat7890-damietta-university/huggingface' target=\"_blank\">https://wandb.ai/reem-ref3aat7890-damietta-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/reem-ref3aat7890-damietta-university/huggingface/runs/6f9m3zzn' target=\"_blank\">https://wandb.ai/reem-ref3aat7890-damietta-university/huggingface/runs/6f9m3zzn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2630' max='2630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2630/2630 02:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.504400</td>\n",
       "      <td>0.385133</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.333272</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.355300</td>\n",
       "      <td>0.311994</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.358400</td>\n",
       "      <td>0.351229</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.340038</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.289485</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>0.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.335100</td>\n",
       "      <td>0.287465</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.314500</td>\n",
       "      <td>0.284112</td>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.313400</td>\n",
       "      <td>0.288931</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.951000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2630, training_loss=0.3599591302327783, metrics={'train_runtime': 248.8738, 'train_samples_per_second': 84.38, 'train_steps_per_second': 10.568, 'total_flos': 706603239165360.0, 'train_loss': 0.3599591302327783, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ouAV7LI3gyoJ",
    "outputId": "b1dc7f0d-464c-45b2-f7b9-7ff61a9e780f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': np.float64(0.891), 'AUC': np.float64(0.945)}\n"
     ]
    }
   ],
   "source": [
    "# apply model to validation dataset\n",
    "predictions = trainer.predict(tokenized_data[\"validation\"])\n",
    "\n",
    "# Extract the logits and labels from the predictions object\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Use your compute_metrics function\n",
    "metrics = compute_metrics((logits, labels))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0j6SktCEjjZW"
   },
   "source": [
    "Run inference on new examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijKcL7beh8kX",
    "outputId": "860580e6-5264-487f-bc31-363d4624bb27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: Tesla T4\n",
      "Predicted label: Unsafe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU instead.\")\n",
    "\n",
    "# Move your model to the appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "input_text = \"000mclogin.micloud-object-storage-xc-cos-static-web-hosting-qny.s3.us-east.cloud-object-storage.appdomain.cloud\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Map prediction to label\n",
    "predicted_label = model.config.id2label[predictions.item()]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofQm60sqiEpn",
    "outputId": "806d4a32-a05a-4952-dfdb-99d60915ba09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Safe\n"
     ]
    }
   ],
   "source": [
    "input_text = \"www.google.com\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Map prediction to label\n",
    "predicted_label = model.config.id2label[predictions.item()]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmWqtBnGiQOG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
